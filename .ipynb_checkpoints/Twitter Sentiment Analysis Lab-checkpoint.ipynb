{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://weclouddata.s3.amazonaws.com/images/logos/wcd_logo_new_2.png\" width='30%'> \n",
    "</center>\n",
    "\n",
    "----------\n",
    "\n",
    "<h1 align=\"center\"> Twitter Sentiment Analysis Lab </h1>\n",
    "<br>\n",
    "<center align=\"left\"> <font size='4'>  Developed by: </font><font size='4' color='#33AAFBD'>WeCloudData</font></center>\n",
    "<br>\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "> The use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information.\n",
    "\n",
    "\n",
    "Demo: https://azure.microsoft.com/en-ca/services/cognitive-services/text-analytics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data preparation & visualisation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Library to assign sentiment to texts\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1083193473539420160</td>\n",
       "      <td>2019-01-10 02:47:03</td>\n",
       "      <td>@CIBC please explain to me why I want to remai...</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1083191479215026176</td>\n",
       "      <td>2019-01-10 02:39:08</td>\n",
       "      <td>RT @CIBCLiveLabs: We are pleased to announce, ...</td>\n",
       "      <td>Oshawa, Ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1083184422709575683</td>\n",
       "      <td>2019-01-10 02:11:05</td>\n",
       "      <td>CIBC World Markets Inc. Decreases Holdings in ...</td>\n",
       "      <td>The Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1083182915826126848</td>\n",
       "      <td>2019-01-10 02:05:06</td>\n",
       "      <td>Le patron de la Banque @cibc s’attend à un ral...</td>\n",
       "      <td>Montréal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1083177871881818112</td>\n",
       "      <td>2019-01-10 01:45:03</td>\n",
       "      <td>Your home is a valuable asset. Use your equity...</td>\n",
       "      <td>Lower Mainland, BC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1083193473539420160  2019-01-10 02:47:03   \n",
       "1  1083191479215026176  2019-01-10 02:39:08   \n",
       "2  1083184422709575683  2019-01-10 02:11:05   \n",
       "3  1083182915826126848  2019-01-10 02:05:06   \n",
       "4  1083177871881818112  2019-01-10 01:45:03   \n",
       "\n",
       "                                                text            location  \n",
       "0  @CIBC please explain to me why I want to remai...              Canada  \n",
       "1  RT @CIBCLiveLabs: We are pleased to announce, ...     Oshawa, Ontario  \n",
       "2  CIBC World Markets Inc. Decreases Holdings in ...     The Netherlands  \n",
       "3  Le patron de la Banque @cibc s’attend à un ral...            Montréal  \n",
       "4  Your home is a valuable asset. Use your equity...  Lower Mainland, BC  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data\n",
    "df = pd.read_csv('tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Labels\n",
    "\n",
    "To perform sentiment analysis and build a model, we would need to label each tweet with its sentiment. To do this, we could manual label the data ourselves by reading each tweet and assigning a positive or negative sentiment. This would be a long and tedious process. A better solution would be to outsource this process by paying for a service such as Amazon Mechanical Turk.\n",
    "\n",
    "> Amazon Mechanical Turk (MTurk) is a crowdsourcing marketplace that makes it easier for individuals and businesses to outsource their processes and jobs to a distributed workforce who can perform these tasks virtually. This could include anything from conducting simple data validation and research to more subjective tasks like survey participation, content moderation, and more. MTurk enables companies to harness the collective intelligence, skills, and insights from a global workforce to streamline business processes, augment data collection and analysis, and accelerate machine learning development.\n",
    "\n",
    "https://www.mturk.com/\n",
    "\n",
    "For our project, we're going to simulate this process by using `TextBlob` to assign the labels. We'll then train a machine learning model to see if we can get similar performance.\n",
    "\n",
    "https://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to assign sentiments (positive, negative or neutral)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        return 'positive'\n",
    "    elif sentiment < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1083193473539420160</td>\n",
       "      <td>2019-01-10 02:47:03</td>\n",
       "      <td>@CIBC please explain to me why I want to remai...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1083191479215026176</td>\n",
       "      <td>2019-01-10 02:39:08</td>\n",
       "      <td>RT @CIBCLiveLabs: We are pleased to announce, ...</td>\n",
       "      <td>Oshawa, Ontario</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1083184422709575683</td>\n",
       "      <td>2019-01-10 02:11:05</td>\n",
       "      <td>CIBC World Markets Inc. Decreases Holdings in ...</td>\n",
       "      <td>The Netherlands</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1083182915826126848</td>\n",
       "      <td>2019-01-10 02:05:06</td>\n",
       "      <td>Le patron de la Banque @cibc s’attend à un ral...</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1083177871881818112</td>\n",
       "      <td>2019-01-10 01:45:03</td>\n",
       "      <td>Your home is a valuable asset. Use your equity...</td>\n",
       "      <td>Lower Mainland, BC</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1083193473539420160  2019-01-10 02:47:03   \n",
       "1  1083191479215026176  2019-01-10 02:39:08   \n",
       "2  1083184422709575683  2019-01-10 02:11:05   \n",
       "3  1083182915826126848  2019-01-10 02:05:06   \n",
       "4  1083177871881818112  2019-01-10 01:45:03   \n",
       "\n",
       "                                                text            location  \\\n",
       "0  @CIBC please explain to me why I want to remai...              Canada   \n",
       "1  RT @CIBCLiveLabs: We are pleased to announce, ...     Oshawa, Ontario   \n",
       "2  CIBC World Markets Inc. Decreases Holdings in ...     The Netherlands   \n",
       "3  Le patron de la Banque @cibc s’attend à un ral...            Montréal   \n",
       "4  Your home is a valuable asset. Use your equity...  Lower Mainland, BC   \n",
       "\n",
       "  sentiment  \n",
       "0   neutral  \n",
       "1  positive  \n",
       "2   neutral  \n",
       "3   neutral  \n",
       "4  positive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each text has a sentiment attached to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter EDA and Feature Engineering\n",
    "\n",
    "Now that we have our data let's explore and analyze it. This is known as **exploratory data analysis** or **EDA**.\n",
    "\n",
    "> exploratory data analysis (EDA) is an approach analyzing data sets to summarize their main characteristics, often with visual methods.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Exploratory_data_analysis\n",
    "\n",
    "--------\n",
    "\n",
    "We can then manipulate the data to create **features** for our machine learning model.\n",
    "\n",
    "> Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. The need for manual feature engineering can be obviated by automated feature learning. Feature engineering is an informal topic, but it is considered essential in applied machine learning.\n",
    "\n",
    "\"Coming up with features is difficult, time-consuming, requires expert knowledge. \"Applied machine learning\" is basically feature engineering.\"\n",
    "\n",
    "— Andrew Ng, Machine Learning and AI via Brain simulations[1]\n",
    "\n",
    "https://en.wikipedia.org/wiki/Feature_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Data exploration\n",
    "\n",
    "- Read in the tweets data using `pandas`\n",
    "- Explore the data\n",
    "\n",
    "Some ideas of things to look for:\n",
    "- the dimensions of the data\n",
    "- get DataFrame info\n",
    "- get summary statistics\n",
    "- get the value counts of categoric columns\n",
    "- count missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1951, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 1951 rows & 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1951 entries, 0 to 1950\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          1951 non-null   int64 \n",
      " 1   created_at  1951 non-null   object\n",
      " 2   text        1951 non-null   object\n",
      " 3   location    1509 non-null   object\n",
      " 4   sentiment   1951 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 76.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Location has several missing values (442)\n",
    "- 'id' is a unique random number generated for each row or tweet - this can be dropped from analysis\n",
    "- 'created_at' of object type & can be converted into datetime datatype\n",
    "- 'text', 'location' & 'sentiment' are of object type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1951.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1081533701646879872.0</td>\n",
       "      <td>1119671716919130.375</td>\n",
       "      <td>1079519007336812544.0</td>\n",
       "      <td>1080580754891984896.0</td>\n",
       "      <td>1081337996031545344.0</td>\n",
       "      <td>1082675320935829504.0</td>\n",
       "      <td>1083193473539420160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "      <td>1951</td>\n",
       "      <td>1924</td>\n",
       "      <td>2019-01-08 20:15:59</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1951</td>\n",
       "      <td>1768</td>\n",
       "      <td>RT @NHLBlackhawks: Staying warm never looked s...</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>1509</td>\n",
       "      <td>428</td>\n",
       "      <td>Canada</td>\n",
       "      <td>355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>1951</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count unique                                                top  \\\n",
       "id          1951.0    NaN                                                NaN   \n",
       "created_at    1951   1924                                2019-01-08 20:15:59   \n",
       "text          1951   1768  RT @NHLBlackhawks: Staying warm never looked s...   \n",
       "location      1509    428                                             Canada   \n",
       "sentiment     1951      3                                            neutral   \n",
       "\n",
       "           freq                   mean                   std  \\\n",
       "id          NaN  1081533701646879872.0  1119671716919130.375   \n",
       "created_at    4                    NaN                   NaN   \n",
       "text         25                    NaN                   NaN   \n",
       "location    355                    NaN                   NaN   \n",
       "sentiment   846                    NaN                   NaN   \n",
       "\n",
       "                              min                    25%  \\\n",
       "id          1079519007336812544.0  1080580754891984896.0   \n",
       "created_at                    NaN                    NaN   \n",
       "text                          NaN                    NaN   \n",
       "location                      NaN                    NaN   \n",
       "sentiment                     NaN                    NaN   \n",
       "\n",
       "                              50%                    75%  \\\n",
       "id          1081337996031545344.0  1082675320935829504.0   \n",
       "created_at                    NaN                    NaN   \n",
       "text                          NaN                    NaN   \n",
       "location                      NaN                    NaN   \n",
       "sentiment                     NaN                    NaN   \n",
       "\n",
       "                              max  \n",
       "id          1083193473539420160.0  \n",
       "created_at                    NaN  \n",
       "text                          NaN  \n",
       "location                      NaN  \n",
       "sentiment                     NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most common sentiment is 'neutral' and it occurs 846 times (out of 1951 records)\n",
    "- The most common location is 'Canada' which occurs 355 times (out of 1951 records). There are 428 unique records under location\n",
    "- Some of the texts have frequency > 1, this indicates the texts have been retweeted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicate records \n",
    "df.duplicated().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are no duplicate records in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "created_at      0\n",
       "text            0\n",
       "location      442\n",
       "sentiment       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Except for location column, none of the other columns have any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     846\n",
       "positive    800\n",
       "negative    305\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts of categorical columns\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Canada                    355\n",
       "Toronto, Ontario           74\n",
       "The Caribbean              64\n",
       "Toronto                    57\n",
       "Jamaica                    35\n",
       "                         ... \n",
       "Toronto via Elmvale         1\n",
       "Toronto Ontario Canada      1\n",
       "646.698.3432                1\n",
       "Rouen                       1\n",
       "Kingston, Ontario           1\n",
       "Name: location, Length: 428, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Create features from datetime\n",
    "\n",
    "- Check the type of the `created_at` column\n",
    "- Convert the `created_at` column to a `datetime` type\n",
    "- Create a new column called `hour` with the hour from `created_at`\n",
    "- Create a new column called `day_of_week` with the `dayofweek` from `created_at`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_at'] = pd.to_datetime(df['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['created_at'].dt.hour\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'] = df['created_at'].dt.dayofweek # 0 = Monday and 6 = Saturday\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Dealing with text data\n",
    "\n",
    "Pandas has many methods for working with text data. We can use these to create features from our tweet text.\n",
    "\n",
    "A full list of these string methods can be found at: https://pandas.pydata.org/pandas-docs/stable/text.html\n",
    "\n",
    "- Create a new column called `num_chars` that is the number of characters in each tweet\n",
    "- Create a new column called `num_words` that is a count of how many words in each tweet \n",
    "- Create a new column called `num_ats` that is a count of how many `@` symbols in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_chars'] = df['text'].str.len()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['text'].str.count(' ') + 1\n",
    "#Note 1: Not everything that is separated is a word\n",
    "#Note 2: +1 is to consider the last word\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_ats'] = df['text'].str.count('@')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Positive and negative words count\n",
    "\n",
    "Sometimes we might want to use external data to help build features. Here we count how positive and negative words there are in each tweet by comparing them to a predefined list of words.\n",
    "\n",
    "We borrow our list of pos/neg words from this study: https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = pd.read_csv('twitter-ml-lab/positive-words.txt', skiprows=35, names=['words'])\n",
    "pos_words = pos_words['words'].values.tolist()\n",
    "pos_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = pd.read_csv('twitter-ml-lab/negative-words.txt', skiprows=35, names=['words'])\n",
    "neg_words = neg_words['words'].values.tolist()\n",
    "\n",
    "neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(tweet, words): #This function should work using pos_words and neg_words\n",
    "    count = 0\n",
    "    for word in tweet.split(' '):\n",
    "        if word in words:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos_count'] = df['text'].apply(count_words, words = pos_words) #.apply(func_name, parameters)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the line above\n",
    "lists = []\n",
    "for text in df['text']:\n",
    "    lists.append(count_words(text, pos_words))\n",
    "df['pos_count'] = lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['neg_count'] = df['text'].apply(count_words, words = neg_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Analysis and visualization\n",
    "\n",
    "- Explore the new **features** we've created\n",
    "- Try and perform your own analysis and see if you can find any interesting insights\n",
    "- Create some visualizations to further analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['day_of_week'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['pos_count'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas-profiling\n",
    "1. Consider how many features you have - More features, slower the cell will run\n",
    "2. Think about if you need all those graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Machine Learning\n",
    "\n",
    "- Get your new features and the label\n",
    "- Split the data into a training and test set with test_size 0.25 and random_state 2019\n",
    "- Try training different models and tune their hyperparameters\n",
    "- Get the model with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier #model\n",
    "from sklearn.metrics import classification_report #metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_test_split\n",
    "# X = df.drop(columns=['sentiment','id','location','created_at','text'])\n",
    "X = df[['hour','day_of_week','num_words','num_chars','num_ats','pos_count','neg_count']] #Remember there is two [] for X\n",
    "y = df['sentiment'] # Only one []\n",
    "\n",
    "# train_test_split: X, y, and test_size are required parameters, random_state is optional\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train, y_train) #Both train sets\n",
    "\n",
    "y_pred = rfc.predict(X_test) #Only X_test, do NOT include y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not recommended this method\n",
    "RandomForestClassifier().fit(X_train, y_train)\n",
    "RandomForestClassifier().predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps of Machine Learning:\n",
    "\n",
    "1. Imports\n",
    "2. Load your data\n",
    "3. EDA - Exploratory Data Analysis\n",
    "4. Cleaning/Feature Engineering\n",
    "5. Visualization\n",
    "6. X, y, train test split\n",
    "7. Scaling is when there is a very big difference in the values between features\n",
    " - Scale is same as model, fit on train, transform on train and test\n",
    "8. Model (baseline model)\n",
    "9. Evaluate\n",
    "10. Do more (feature selection, hyperparameter tuning, feature engineering, ask for more data, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston #Other datasets available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
